\subsection{Resultados do CINTIL}
\label{resultados_cintil}
Nesta sessão, demonstraremos os resultados obtidos com a transdução do CINTIL.

\subsubsection{Treinamento} 
\label{result_treino_cintil}

Na Tabela \ref{tab:resultados_treino_cintil}, podemos ver o relatório de treinamento de cada execução do SP com o CINTIL transduzido.
\begin{center}
    \input{tabelas/tab_cintil_result_treino.tex}
\end{center}

% Pode-se notar que bons resultados de treino são obtidos apenas com o primeiro \textit{fold}, cujos resultados superam os outros \textit{folds}. 
Pode-se notar que, além do primeiro \textit{fold} (que abrange os últimos nove décimos do \textit{treeebank} para treinamento, e reserva o primeiro para testes), os resultados são bastante semelhantes. Deduz-se, então, que o primeiro décimo do \textit{dataset} é muito relevante no processo de treino. O sexto \textit{fold} (reserva a 6ª parte para testes) parece ser o com melhores resultados gerais. 
Melhor visualizado na Figura \ref{fig:treino_cintil}.
\begin{center}
    \input{imagens/cintil_treino_result.tex}
\end{center}

As colunas necessitam de explicações, cuja coleta foi trabalhosa. O FAQ do SP é pouco informativo, e o do CoreNLP possui a mesma dificuldade.

Pelo código-fonte do SP\footnote{A referência foi a classe LexicalizedParser.java, que está disponível em \url{https://github.com/chbrown/stanford-parser/blob/master/edu/stanford/nlp/parser/lexparser/LexicalizedParser.java}}, \textit{States} representa a quantidade de Índices de Estado. Inferiu-se que é a quantidade de estados de transição da gramática gerada pelo treino. 

\textit{Tags}, por sua vez, representa a quantidade de Índices de \textit{Tags}. Seria a quantidade de \textit{Tags} registradas durante o treino (note que o número varia pouco).

\textit{Words}, de forma análoga, representa a quantidade de Índices de Palavras. Deduz-se que, a quantidade de palavras distintas verificadas pelo treinamento.

\textit{UnaryR} e \textit{BinaryR} correspondem, respectivamente, às quantidades de regras das gramáticas Unária e Binária. A descrição de ambas classes é, na sequencia, \textquote{\textit{Maintains efficient indexing of unary grammar rules}} e \textquote{\textit{Maintains efficient indexing of binary grammar rules}}. Pelo Javadoc do SP\footnote{\url{https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/parser/lexparser/package-summary.html}},
\begin{quote}
    \begin{itemize}
        \item \textit{Unary Grammar - consists of unary rewrite rules, one per line, each of which is of the form A -> B, followed by the normalized log probability.}
        \footnote{Gramática Unária - consiste em regras de reescrita unárias, uma por linha, cada qual na forma A -> B, seguida pela probabilidade log normalizada}
        \item \textit{Binary Grammar - consists of binary rewrite rules, one per line, each of which is of the form A -> B C, followed by the normalized log probability.}
        \footnote{Gramática Binária - consiste em regras de reescrita binárias, uma por linha, cada qual na forma A -> B C, seguida pela probabilidade log normalizada}
    \end{itemize}
\end{quote}

Cabe frisar que tal modelo, utilizando regras unárias e binárias, segue o padrão da Forma Normal de Chomsky, que pode ser visto em \cite[p~389]{Manning1999FoundationsNLP}.

Por fim, \textit{Taggings} se refere à \textquote{\textit{[\ldots]the number of rules (tag rewrites as word) in the Lexicon.}}
\footnote{o número de regras (etiquetas reescritas como palavras) no Lexicon}.
Lexicon é uma interface, descrita como
\begin{quote}
    \textquote{\textit{An interface for lexicons interfacing to lexparser. Its primary responsibility is to provide a conditional probability P(word|tag), which is fulfilled by the {\#score} method. Inside the lexparser, Strings are interned and tags and words are usually represented as integers.}}
    \footnote{\textquote{Uma interface entre lexicons e o lexparser. Sua responsabilidade primária é prover uma probabilidade condicional P(palavra|etiqueta), que é preenchida pelo método \textit{\#score}. Dentro do \textit{lexparser}, \textit{Strings} são representadas canonicamente, e etiquetas e palavras são geralmente representadas por inteiros}. Tradução própria.}
\end{quote}

\subsubsection{Avaliação} 
\label{result_aval_cintil}

Nos apêndices, a Tabela \ref{tab:cintil_result_full} traz os resultados completos de nossos testes com o CINTIL. Vamos usar, aqui, versões reduzidas dos dados.

Começando pelos dados da PCFG interna ao LexicalizedParser, podemos ver o seu resultado na Tabela \ref{tab:result_cintil_pcfg}, e na Figura \ref{fig:cintil_result_pcfg}.
\begin{center}
    \input{tabelas/tab_resultados_cintil_pcfg.tex}
\end{center}

A média da \textit{F1-Score} é 59.304\%, e seu desvio padrão é de aprox. 4.208\%.

Fica claro que a simples transdução de árvores da língua portuguesa para os padrões da língua inglesa, conservando as palavras, é insuficiente para o bom resultado do \textit{parser}.

% Nota-se, também, que para classificações mais eficientes, bastaria utilizar o primeiro décimo do CINTIL, pois tal bloco superou todos os outros durante o treino.
\begin{center}
    \input{imagens/cintil_result_pcfg.tex}
\end{center}

\subsubsection{Estudos de caso}
\label{subsec:ec_cintil}

Separamos alguns exemplos de sentenças transduzidas, classificadas pelo \textit{Stanford Parser}. Serão exibidas as sentenças já em formato de árvore. As imagens foram produzidas no \textit{website} jsSyntaxTree\footnote{\url{http://www.ironcreek.net/syntaxtree/}}.

O \textit{parsing} do PS é feito executando o comando \ref{lst:cod_parsing_cintil}. Note que utilizamos a gramática treinada pelo sexto \textit{fold}.
\begin{center}
    \input{codigos/cod_parsing_cintil.tex}
\end{center}

Explicando rapidamente na Tabela \ref{tab:tab_exec_basico_cintil}.

\begin{center}
    \input{tabelas/tab_CintilExecBasica.tex}
\end{center}

\begin{center}
    \input{imagens/ec_cintil_sem_ponto_tree.tex}
\end{center}

Na Figura \ref{fig:ec_cintil_sem_ponto_tree}, vemos o resultado da classificação de uma sentença originalmente sem pontuações. Há algumas coisas interessantes a serem notadas. Se, por um lado, de fato a falta de pontuação ajudou no \textit{parsing}, 
% por outro o SP tem dificuldades em separar contrações de preposições.
as contrações de preposição (\textquote{à}, \textquote{no}) não são identificados. O que faz sentido, pois o treino foi feito considerando tais separações.

\begin{center}
    \input{imagens/ec_cintil_conjp_tree.tex}
\end{center}

A Figura \ref{fig:ec_cintil_conjp_tree} nos dá mais material de interesse. 
% Por exemplo, pode-se notar como a ausência de conhecimento de léxico da língua classificada gera confusões. 
% O \textquote{o} é facilmente confundido, mas não apenas. 
% O sintagma CONJP, que some na árvore transduzida, retorna na árvore classificada. Interessante notar que a 
% que a transforma num adjunto de VP. 
% O sintagma VP, em \textquote{não podia} tem seu núcleo, e por conseguinte, o sintagma como um todo, alterado. Provavelmente, para seguir a tendência da língua inglesa, que costuma ter o núcleo do sintagma posicionado mais à direita \cite[p~40]{charniak97statistical}. 
% A confusão com as pontuações é notável, sendo transformadas em substantivo (NNS) ou verbo (VB), o que é curioso. 
% Supões-se que o SP não seja estranho à pontuações mesmo que elas não venham no seu conjunto de treino.
A confusão gerada pela falta de treinamento sobre pontuações permanece, sendo ainda uma das maiores falhas. O $VP_3$ \textquote{não aconteça} se torna um $ADJP$, considerando como núcleo o advérbio \textquote{não}. O esforço de manter a estrutura de conjunções, que estudamos na Seção \ref{subsec-cintil-conj} é desfeito, convertendo o sintagma solto em \textit{flat structure} \textquote{para que} se converte num PP. Vale notar que ele não se torna um sintagma conjuntivo (CONJP), e \textquote{que} não é marcado como CC, que é a tendência tradicional do \textit{parser}. Também, apesar da tendência da língua inglesa, que costuma ter o núcleo do sintagma posicionado mais à direita \cite[p~40]{charniak97statistical}, isso não ocorre nem no PP, nem no ADJP.

\begin{center}
    \input{imagens/ec_cintil_cp_tree.tex}
\end{center}

Verificando as alterações realizadas sobre o sintagma CP, como vimos na Seção \ref{subsec-cintil-c}, vejamos a Figura \ref{fig:ec_cintil_cp_tree}. Curiosamente, o sintagma em questão está acompanhando bem a estrutura da árvore original, e da árvore transduzida. 
% O maior destaque ficam para as palavras de classe aberta (substantivos, verbos, adjetivos). Aparentemente, a informação léxica continua sendo um problema.
\begin{center}
    \input{imagens/ec_cintil_virgula_tree.tex}
\end{center}

Para finalizar nossa revisão com as transduções do CINTIL, temos a Figura \ref{fig:ec_cintil_virgula_tree}, a respeito da colocação de vírgulas.
Pode-se notar a dificuldade léxica, onde palavras como \textquote{vistos} e \textquote{adiadas} são confundidos. Acredita-se que, se a contração da palavra \textquote{pelos} fosse detectada, a presença do Determinante resolveria tal problema. Os erros de marcação destes terminais afetam toda a marcação da árvore acima. Curioso notar também que, sem o treino de pontuações, tais símbolos se tornam ou substantivos (NNS), ou adjetivos (JJ). Porém, nem sempre são marcadas da mesma maneira, como pode ser comparado entre as Figuras \ref{fig:ec_cintil_virgula_tree} e \ref{fig:ec_cintil_conjp_tree}.
% Nota-se uma tendência muito interessante, do SP, de considerar palavras como adjetivo (JJ). Mesmo para palavras que nunca assumem tal forma, como \textquote{pelos}, que pode ser ou a contração \textit{por + os}, ou um substantivo. A falta de treinamento com pontuações mais uma vez é sentida, uma vez que SP não sabe como resolver vírgulas e pontos.