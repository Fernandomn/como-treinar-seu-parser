% ----------------------------------------------------------
% Introdução (exemplo de capítulo sem numeração, mas presente no Sumário)
% ----------------------------------------------------------
\chapter{Introdução}
\label{cha:introducao}
% ----------------------------------------------------------
% \begin{quote}
%     \textquote{O mundo é mediado pela linguagem} \cite{oliveira2019servico}
%     \footnote{É claro que uma reflexão tão bonita não teria sido gerada por mim. Muita gente já falou isso antes de mim, \citeonline{spolador2018mediadora} e \citeonline{baccega1995palavra} para citar exemplos.}
% \end{quote}
\textquote{O mundo é mediado pela linguagem} \cite{oliveira2019servico}
\footnote{Esta é um,  citar \citeonline{spolador2018mediadora} e \citeonline{baccega1995palavra} como referências.}
, no sentido que, interações humanas são realizadas a partir da linguagem, ou interpretadas com base nela. 
% \textquote{Mas e quando eu chuto uma pedra? Eu só uso a linguagem pra xingar ela!}.
Pode-se pensar, então, em situações nas quais a linguagem \textquote{não é} diretamente usada, como ao chutar uma pedra.
% Bom, você interpreta toda a situação se valendo da linguagem para fazê-lo. 
Porém, toda a situação é interpretada se valendo da linguagem para fazê-lo. 
A saber, quando se lembra do ocorrido, quando se comenta sobre etc. O falar, o ler e o ouvir tem peso fundamental no domínio da linguagem e, por conseguinte, na compreensão de mundo.

\citeonline[p~33]{fanon2008pele} afirma: \textquote{Falar é estar em condições de empregar uma certa sintaxe, possuir a morfologia de tal ou qual língua, mas é sobretudo assumir uma cultura, suportar o peso de uma civilização}. E complementa (\textit{\Ibidem[p~33]{fanon2008pele}}) \textquote{Um homem que possui a linguagem possui, em contrapartida, o mundo que essa linguagem expressa e que lhe é implícito}. Dominar a língua, ser capaz de interpretá-la e articulá-la, d
á ao indivíduo uma série de possibilidades. Não só o poder de influência, mas o poder do reconhecimento como pessoa, (\textit{\Ibidem[p~33]{fanon2008pele}}) \textquote{Uma vez que falar é existir absolutamente para o outro}.

% Não é de surpreender, portanto, que a partir do momento que possuímos ferramentas tão poderosas como computadores, desejemos que elas sejam capazes de falar e compreender linguagem humana. Este não é um desejo novo. Pelo contrário, 
Desde a origem da computação, existe o desejo em fazer com que computadores sejam capazes de processar linguagem.
Quando \citeonline[p~433]{turingJogoImitacao}, nos pede que consideremos a questão \textquote{Podem as máquinas pensar?},
% \textit{Can machines think?}}\footnote{\textquote{Podem as máquinas pensar?}. Tradução própria.}
a forma sugerida para que o famoso Jogo da Imitação seja operado é, essencialmente, uma troca de mensagens, ou seja, o uso livre da linguagem. 

% % Sendo um pouco mais pragmático, já 
% Em 1956 acontece o \textit{Dartmouth Summer Research Project on Artificial Intelligence}\footnote{\textquote{Projeto de Pesquisa de Verão em Inteligência Artificial de Dartmouth}. Tradução própria.}, em New Hampshire, Estados Unidos, que viria a ser conhecido como a origem da Inteligência Artificial (I.A.) como conhecemos hoje. Seu nome foi cunhado por um dos idealizadores, John Mccarthy. O evento termina sem uma concordância entre metodologias e problemas comuns da teoria geral. Pelo contrário, como vemos em \cite[p~87]{Moor2006DartmouthIA}, na proposta da conferência constava:
% \begin{quote}
%     \textquote{O estudo deve seguir com base da conjectura que todo aspecto do aprendizado ou qualquer outra característica da inteligência pode, em princípio, ser tão precisamente descrito, que uma máquina pode ser feita para simulá-lo.}
%     \footnote{ \textquote{\textit{The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it.}} Tradução própria.}
%     \footnote{Pode-se trazer visões distintas acerca do tópico. Turing, em \citeonline[p~442]{turingJogoImitacao} postula: \textquote{A visão popualr de que cientistas procedem inexoravelmente de fatos bem estabelecidos para fatos bem estabelecidos, nunca sendo influenciados por qualquer conjectura sem probas, é bastante errônea} (Tradução própria). 
%     % \textquote{The popular view that scientists proceed inexorably from well-established fact to well-established fact, never being influenced by any unproved conjecture, is quite mistaken}. 
%     Já Minsky como visto em \cite[p~87]{Moor2006DartmouthIA}, demonstra descontentamento com o andamento da área. \textquote{Minksy expressou a preocupação de que muitos na IA hoje em dia tentam fazer o que é popular e publicam apenas o que tem sucesso. Ele argumenta que IA nunca poderá ser uma ciência até que se publique o que falha assim como o que tem sucesso.} Tradução própria).
%     % \textquote{Minsky expressed the concern that too many in AI today try to do what is popular and publish only successes. He argued that AI can never be a science until it publishes what fails as well as what succeeds.}
%     }
% \end{quote}

A interpretação da linguagem por meios automáticos é uma das várias áreas que a Inteligência Artificial (I.A.) estuda, chamada de PLN (Processamento de Linguagem Natural, ou NLP em inglês). 
% Que pode atrair, obviamente, muitos olhares poderosos.
\citeonline{oquepln2017rodrigues} resume:
\begin{quote}
    \textquote{O objetivo do PLN é fornecer aos computadores a capacidade de entender e compor textos. \textquote{Entender} um texto significa reconhecer o contexto, fazer análise sintática, semântica, léxica e morfológica, criar resumos, extrair informação, interpretar os sentidos, analisar sentimentos e até aprender conceitos com os textos processados.}
\end{quote}

PLN é muito estudada como ciência de base, ou até mesmo por empresas para a criação de produtos como \textit{chatbots} e Assistentes Pessoais, para citar exemplos cotidianos. 
% Além disto, PLN pode ser estudado como recurso político e estratégico.

% Entre 1987 e 1997 aconteceram as \textit{Message Understanding Conference} (MUC)\footnote{\textquote{Conferência de Compreensão de Mensagens}. Tradução própria.}. Como visto em \cite[p~466]{Grishman1996MUC}, foram organizadas pela NRAD\footnote{\textquote{\textit{Naval Research And Development}}, Desenvolvimento e pesquisa Naval}, uma divisão da RDT\&E\footnote{\textquote{\textit{Research, Development, Test \& Evaluation}}, Pesquisa, Desenvolvimento, Teste e Avaliação} do Centro de Comando Naval, Controle, e Vigilância Oceânica (antiga NOSC, Centro de Sistemas Oceânico Navais), com apoio da DARPA, a Agência de Projetos de Pesquisa de Defesa Avançada. Na conferência, diversos testes eram feitos, onde os participantes recebiam provas de Extração de Informação, visando obter dados valiosos de documentos.\footnote{\textquote{Curiosamente}, já na sua terceira edição, o MUC-3, os documentos base se tornaram relatórios sobre terrorismo na América do Sul e Central, o que mostra a atenção política dada pelos EUA ao Cone Sul.}

% De quais formas podemos ensinar um computador a ler e escrever? Diversas, na verdade. 
Uma das formas de utilizar a linguagem computacionalmente é a Classificação Sintática Automatizada. Como definido por \citeonline[p~33]{charniak97statistical}, \textquote{Classificação sintática automatizada é o processo de atribuir um marcador de sintagma a uma sentença
\footnote{No original: \textit{Syntactic parsing is the process of assigning a phrase marker to a sentence}}
}.
% Ou seja, lembra na escola, quando você tinha que fazer a análise sintática de \textquote{João ganhou a bola}? 
Ou seja, realizar a análise sintática de sentenças como \textquote{João ganhou a bola} é definir, por exemplo, que João é substantivo, ganhou é verbo etc. Classificação automatizada diz respeito à construção de sistemas computacionais que realizem tal tarefa.

% Tenta-se, até hoje, achar
Ainda se pesquisam métodos baseados em lógica para realizar tal tarefa. Porém, 
% o que anda em voga 
a tendência atual são os métodos estatísticos. Como definido em \citeonline[p~37]{charniak97statistical},
\begin{quote}
    \textquote{Classificadores estatísticos funcionam atribuindo probabilidades para possíveis classificações (árvores) de uma sentença, localizando a árvore mais provável, e então apresentando tal árvore como resposta. Também, para construir um \textit{parser} estatístico, deve-se descobrir como (1) encontrar possíveis árvores, (2) atribuir probabilidades para elas, e (3) devolver a mais provável.}
    \footnote{No original: \textquote{\textit{Statistical parsers work by assigning probabilities to possible parses of a sentence, locating the most probable parse, and then presenting the parse as the answer. Thus, to construct a statistical parser, one must figure out how to (1) find possible parses, (2) assign probabilities to them, and (3) pull out the most probable one.}}}
    (Tradução própria)
\end{quote}
% E porque utilizar a estatística, ao invés de regras bem estabelecidas? 
Para que tenham bom funcionamento, \textit{parsers} precisam ser treinados com um conjunto de sentenças pré-classificadas. A essas sentenças damos o nome de \textit{árvores}, e ao seu conjunto, o nome de Banco de Árvores, ou \textit{treebanks} (como serámelhor explicado em \ref{sec:parser}).

Ao leitor pode parecer contra-intuitivo, utilizar estatística ao invés de regras pré-definidas. Nas palavras do próprio Charniak, em \cite[p~89]{Moor2006DartmouthIA}:
\begin{quote}
    \textquote{Estatística dominou o processamento de linguagem natural porque funciona}
    \footnote{\textquote{\textit{Statistics has taken over natural language processing because it works.}}}
    (Tradução própria)
\end{quote}
% Como vemos em \cite{kegler2019parsing}, é possível retomar o histórico do estudo de \textit{parsers}\footnote{\textit{\textit{parser}} é o equivalente a classificador sintático na língua inglesa.} a períodos anteriores à era comum,
% mas vamos nos reduzir aos estudos de Ada Lovelace em 1854, com a primeira linguagem de programação, e aos estudos do sr. Rutishauser em 1949, com o primeiro compilador teórico. 
% mas podemos tomar como partida os estudos do Sr. Rutishauser. 
% Pode-se dizer, então, que os estudos sobre \textit{parsers} ocorrem desde 1949, pelo menos.
Por \cite{kegler2019parsing}, conseguimos traçar os estudos modernos de \textit{parsing} desde 1949. 
% \textit{Parsers} tem largo uso tanto para a área de Compiladores, como de PLN (falamos disso em \ref{sec:parsing}). 
Uma busca simples no Google Acadêmico\footnote{scholar.google.com.br} por \textquote{\textit{parser}} nos retorna aproximadamente 320.000 resultados. Pesquisar por \textquote{\textit{natural language processing}} retornará aproximadamente 3.290.000. \textit{Parsers} são quase 10\%
% \footnote{Na verdade, são 9.72\%. Mas você não faz muitos amigos levando as coisas tão ao pé da letra.} 
deste total.

% Uma área tão antiga, certamente tem estudos para o português.
% \footnote{Por que o foco no português? Porque os autores são brasileiros.} 
Fazendo um processo semelhante, buscando por \textquote{\textit{\textit{parser} portuguese}}\footnote{classificador sintático português}, obtemos aproximadamente 10.400 resultados. Quase 3\%.
% Para tantos idiomas no mundo, não é ruim.
% Existem diversos idiomas no mundo, é uma boa fatia.
Já \textquote{classificador sintático português} retorna 15.100 resultados. A pesquisa por  \textquote{\textit{parser english}}, porém, retorna 106.000 resultados. O triplo de resultados em comparação com o verbete anterior.

% Note, não é o objetivo deste trabalho um embate entre lusófonos e anglófonos. Mas, de fato, as pesquisas em PLN sobre a língua portuguesa ainda estão longe de alcançarem números tão expressivos. Claro, a pesquisa existe, é crescente, e demonstra grande entusiasmo e comprometimento dos pesquisadores. No STIL\footnote{\textquote{Symposium in Information and Human Language Technology}, Simpósio em Informação e Tecnologia de Linguagem Humana --  \url{http://www.bracis2019.ufba.br/index.html}} 2019, por exemplo, uma quantidade considerável de trabalhos visava a interpretação, ou o auxílio à pesquisa da língua portuguesa (na forma da criação de \textit{datasets}, por exemplo), com alto nível de qualidade. Existe interesse nos estudos para esta linguagem. Mas, usando o mesmo evento como um micro estudo de caso, poucos trabalhos envolviam a pesquisa com \textit{parsers}\footnote{\url{http://comissoes.sbc.org.br/ce-pln/stil2019/accepted.html}}. O que gerou esse desinteresse? Hipótese:
% \begin{quote}
%     Desenvolver \textit{parsers} não é trivial, mesmo com dados e métodos disponíveis.
% \end{quote}

É compreensível que o número de pesquisas na área para a língua inglesa seja maior do que em português. É importante que se diga, também, que existem \textit{treebanks} robustos para o português. Sente-se falta da conexão entre ambos, \textit{parsers} e dados. Pode-se criar a hipótese, portanto, de que mesmo com dados e métodos disponíveis, o desenvolvimento de \textit{parsers} não é trivial. Isso explicaria a tendência (natural) dos pesquisadores de dedicarem maior esforço para os métodos já desenvolvidos, além de focar em língua com maior expressão global.

Dada a complexidade da tarefa, surge a inquietação que motiva este trabalho: Seria possível desenvolver um \textit{parser} \textit{out-of-the-box}, ou seja, tentando utilizar apenas materiais já desenvolvidos (a saber, \textit{parsers} já existentes, bem como corpus de treino já existentes), de modo que ele seja eficiente?

Sobre \textit{out-of-the-box parser}, seguimos a linha de \citeonline[p~2]{Branco2010OutOfTheBox}, que se propõe a estender pacotes de \textit{software} já disponíveis, que permitam treinar um \textit{parser} robusto a partir de um \textit{treebank}, que seja independente de linguagem e suporte uma aplicação para o português sem grandes problemas.

% Já abordamos as três partes da sentença nessa introdução.
% Como já vimos: O desenvolvimento de \textit{parsers} é bastante expressivo, mas exige tempo e recursos; existem dados que podem ser usados na língua portuguesa, e vêm sendo desenvolvidos cada vez mais; e a comunidade científica já lida com o desenvolvimento deles há bastante tempo. Tem um detalhe, ainda não declarado: é um conhecimento ainda \textquote{fechado} à comunidade científica, e à grandes empresas de tecnologia. 
% % O público geral não conseguiria começar a estudar o desenvolvimento de \textit{parsers} com a mesma praticidade e acolhimento que pessoas que começam a desenvolver \textit{websites}, por exemplo. 
% O público geral conseguiria começar a estudar o desenvolvimento de \textit{parsers} sem grandes dificuldades? De modo semelhante às pessoas que começaram a desenvolver \textit{websites}, por exemplo?
% Temos algumas questões em mãos, e várias delas apresentam dificuldades que podem ser exploradas.
% % vamos explorar essas dificuldades!

% Como já foi dito, vários métodos e vários materiais já existem, e estão disponíveis publicamente para acesso e uso. Porque não trabalhar com isto? Poderíamos usar algum \textit{parser} 
% % em inglês,
% já conhecido, que é utilizado para outras línguas, como a língua inglesa,
% dados em português, e pronto, o sucesso nos aguarda.

% Infelizmente, como espera-se que fique claro com este trabalho, não é simples fazer tal tarefa. Para serem utilizados, \textit{parsers} recebem implementações específicas para a língua que foram desenvolvidos. Mais do que isso, esperam informações que já estejam em formatos específicos, e estes, muitas vezes, são pensados para sua língua de origem, não para idiomas de forma geral.
% Mas essa ideia ainda é boa demais para ser desperdiçada.
% Podemos, então, tentar outra abordagem.
% Porque não \textit{transduzimos} os dados?
Os primeiros testes empíricos foram um fracasso. Os corpus disponíveis não eram recebidos pelos \textit{parsers} que localizamos. Levantou-se, então, uma nova possibilidade: realizar a transdução dos dados de entrada.  
    
% \textquote{Ei, você escreveu errado, é \textquote{traduzir}!}

\textquote{Transdutores} foram explicados por \citeonline[p~1]{Mohri2004}:
\begin{quote}
    \textquote{[Transdutores] São autômatos os quais cada transição, em adição à sua etiqueta de entrada normal, é aumentado com uma etiqueta de saída de um possível novo alfabeto, e carrega algum elemento de peso de um semi anel. Transdutores podem ser usados para definir um mapeamento entre dois tipos diferentes de fontes de informação, por exemplo palavras e sequências de fenômenos}
    \footnote{\textquote{\textit{[Transductors] are automata in which each transition in addition to its usual input label is augmented with an output label from a possibly new alphabet, and carries some weight element of a semiring. Transducers can be used to define a mapping between two different types of information sources, e.g., word and phoneme sequences.}}}
    (Tradução própria)
\end{quote}

% Ou seja, vamos transduzir um conjunto de dados n’outro. Porque não só \textquote{traduzir}? 
% % Porque linguas diferentes têm características diferentes, e precisamos estar prontos para lidar com elas.
% Porque línguas distintas possuem especificidades que tornam complexo o processo de tradução direta. Não só isto, mas como veremos nas próximas páginas, os próprios conjuntos de dados possuem características muito peculiares.
Em suma, neste trabalho, faremos a transdução de conjuntos de dados construídos num certo formato, para um novo formato, e faremos a avaliação deste experimento. Isto nos leva a um segundo produto: o desenvolvimento de uma metodologia de adaptação inter-corpora.

% Após esta introdução, vamos definir o que é cada conceito do projeto, e suas etapas de execução, além de seus resultados.

    
\section{Contexto do Trabalho}
\label{sec:contexto}

O estudo de \textit{parsers} é bastante conhecido do meio acadêmico, tendo muito uso tanto na NLP, como na compilação de linguagens de programação. Também, existe uma produção crescente para o desenvolvimento de tecnologias em NLP para o português, principalmente para as variantes europeia e brasileira. 
% Porém, o estudo de \textit{parsers} para a língua portuguesa parece não receber o mesmo entusiasmo, ficando restrito à melhoria dos sistemas já conhecidos.
Foi sentida, porém, a falta de mais estudos focados na língua portuguesa.

Pesquisas prévias mostraram que existem, sim, \textit{parsers} projetados pensando na língua portuguesa (serão mais abordados na sessão \ref{parser_portugues}). Porém, eram de difícil acesso, ou não era possível utilizá-los. Foram encontrados, também, bancos de dados\footnote{Bancos de Árvores (\textit{treebanks}, que serão melhor explicados em (\ref{treebank}} com dados da língua portuguesa, variantes europeia e brasileira.

Sabendo-se da existência de tecnologias tanto de \textit{parsing} como de textos em português pré-classificados, pensou-se na possibilidade do desenvolvimento \textit{Out-of-the-box}, adaptando tecnologias pré-existentes, e avaliando seus resultados. Não apenas desejando verificar a eficiência de tal método, como analisar quanto estudo técnico é necessário para tal.

Notou-se, contudo, que tal processo de adaptação exige um método ele mesmo. Pois os \textit{parsers} exigem um formato de entrada, que nem sempre é o mesmo formato dos dados disponíveis.

Portanto, foi desenvolvido um método que faça a conversão entre dados de formatos distintos, de modo a que seja possível o uso destes dados no analisador sintático escolhido.

% Com isto queremos, com pouco desenvolvimento, adaptar um \textit{parser} já estabelecido para a língua portuguesa. 

% Por que pouco desenvolvimento? Porque queremos, também, verificar o quão simples seria, para alguém sem conhecimento acadêmico, realizar tal feito.


\section{Objetivo Geral}
\label{sec:objetivos-gerais}
%o que vc quer fazer 
% v1
% O objetivo deste trabalho é transduzir conjuntos de dados do português para o inglês, e verificar se um \textit{parser} conhecido e já utilizado é capaz de ter boa performance, quando recebendo dados de outro idioma para o qual não foi desenvolvido primariamente.
% O objetivo deste trabalho é realizar o treinamento de um \textit{parser} estabelecido, a partir de técnicas \textit{out-of-the-box}\footnote{\textquote{Fora da Caixa}, tradução própria.}, utilizando o mínimo de implementação. Verificar a capacidade de execução deste \textit{parser} a partir de conjuntos de treino originalmente não projetados para este classificador.

% v2
% Este trabalho possui dois objetivos principais. Primeiramente, deseja-se utilizar um \textit{parser} já existente e treiná-lo para a língua portuguesa, utilizando corpora também já existentes da língua portuguesa, e adaptando-os. Em segundo lugar, visa-se a criação de uma metodologia que auxilie o processo de transdução inter-corpora.

Este trabalho tem como objetivo o treinamento de \textit{parsers} já existentes para que sejam capazes de processar a língua portuguesa. A partir de tal treino, avaliar a sua eficiência, taxa de erros e afins.

\section{Objetivos Específicos}\label{sec:objetivos-especificos}
\begin{itemize}
%quebrar o problema grande em subproblemas
    \item Estudar sobre analisadores sintáticos (\textit{parsers});
    \item Fazer o levantamento de florestas sintáticas (\textit{treebanks}) disponíveis na língua portuguesa;
    \item Fazer o levantamento de \textit{parsers} em português;
    \item Definir um \textit{parser} convencional a ser utilizado na pesquisa;
    \item Desenvolver um método de adaptação entre florestas sintáticas; 
    \item Realizar a adptação de florestas sintáticas para utilizar no \textit{parser} definido;
    \item Treinar o \textit{parser} definido com as florestas sintáticas adaptadas;
    \item Avaliar resultados do \textit{parser};
    % \item Testar \textit{parser} com sentenças específicas.
    
\end{itemize}

\section{Justificativa}	
\label{justificativa}

% Ao debater o Processamento de Linguagem Natural, \citeonline[p~10]{vieira2001linguistica} comentam:
% \begin{quote}
%     \textquote{Para lidar com os vários problemas, temos hoje, em nível mundial, uma comunidade científica e acadêmica em crescimento. Há muita pesquisa e trabalhos realizados principalmente para o Inglês, Espanhol, Alemão, Francês e Japonês. Encontramos, porém, carência de pesquisas, ferramentas, recursos linguísticos e humanos para tratar computacionalmente a língua portuguesa.}
% \end{quote}

Como já citado, a quantidade de pesquisas em \textit{parsers} para a língua portuguesa ainda estão em número reduzido com relação aos estudos mundiais. Por observação empírica, nota-se que estão muito focados na reprodução e manutenção de materiais já existentes, e antigos.
\cite[p~371]{Manning1999FoundationsNLP}:
\begin{quote}
    \textquote{Uma avaliação completa de classificadores como pré-processadores úteis para tarefas de NLP multilíngues de alto nível só serão possíveis após resultados experimentais suficientes de uma ampla gama de línguas estiver disponível}
    \footnote{No original: \textquote{\textit{A full evaluation of taggers as useful preprocessors for high-level multilingual NLP tasks will only be possible after sufficient experimental results from a wide range of languages are available.}}}
    (Tradução própria.)
\end{quote}

% Deseja-se que este seja mais um trabalho a acrescentar e fomentar conteúdo para esta subárea de pesquisa.


\section{Metodologia}\label{sec:metodologia}
% O método utilizado para elaboração deste trabalho de conclusão de curso, foi: estudar conjuntos de sentenças já classificadas na língua portuguesa (\textit{treebanks}, serão explicados em \ref{treebank}), e verificar as correspondências destas com o formato aceito pelo \textit{parser} escolhido. A partir de então, verificar quais etiquetas morfossintáticas (\textit{POS tags}, abordadas em \ref{subsec:POStags}) tem correspondência direta, e quais não. As que possuem, foram feitas transduções diretas. As que não, verificar uma correspondência gramatical, e utilizá-las no procedimento. 

% Certas estruturas gramaticais são distintas, por mais que possuam valor sintático semelhante. Para estas, foi necessário fazer a convergência de estrutura, transduzindo assim não só as etiquetas, mas também a morfologia da árvore classificada (\textit{parse tree}, explicadas em \ref{parsing}).

% As sentenças classificadas e transduzidas foram utilizadas para treinar o \textit{parser}. Foram coletados os dados de resultados dos treinos e testes, e e feitas análises baseadas nos métodos abordados em \ref{resultados}. 

O desenvolvimento deste trabalho foi dividido em X etapas.

A Primeira etapa consistiu na revisão bibliográfica. Fez-se necessário o estudo dos classificadores sintáticos, e das florestas sintáticas. 

Para o estudo dos classificadores sintáticos, pesquisou-se no Google Acadêmico\footnote{\url{http://www.scholar.google.com}} por \textit{parsing}, \textit{statistical parsing}, \textit{constituency parsing}, \textit{Neural Networks and parsing}, \textit{Treebank}, \textit{parser comparison}. Foram coletados 10 artigos por assunto pesquisado, que tiveram seu resumo/\textit{abstract} lidos, para avaliação de relevância. Como material base de estudo, foi usado  \cite{Manning1999FoundationsNLP}. Será melhor abordado em \ref{sec:parser}.

Para a pesquisa de florestas sintáticas para o português, pesquisou-se pelas palavras-chave \textit{portuguese treebank}, \textit{treebank português}, \textit{floresta sintática português} em motores de busca como Google Acadêmico e Google\footnote{\url{www.google.com}}. Encontramos o Bosque \cite{bick2008FlorestaSintatica}, do projeto Floresta Sintá(c)tica disponível publicamente, e nos foi cedido o CINTIL \cite{cintil_handbook}. Será explicado em \ref{treebank}.

De forma análoga, pesquisou-se por \textit{parsers} na língua portuguesa nos motores de busca supracitados, com as palavras-chave \textit{portuguese parser}, \textit{parser português}, \textit{classificador sintático português}. Encontramos referências ao PALAVRAS \cite{bick2000palavras} e ao LX-Parser \cite{siteLxParser}. Abordados em \ref{parser_portugues}.

Na Segunda etapa, buscou-se por um \textit{parser} a ser utilizado no projeto. Utilizando-se os motores de busca supracitados, pesquisou-se por \textit{parser}, \textit{parsing}, \textit{constituency parser}. Devido à sua robustez, fácil utilização sem necessidade de desenvolvimento (por comandos de terminal), e por ter amplo reconhecimento na comunidade, optou-se pelo uso do Stanford Parser \cite{fastAccurate}. Este recebe, como entrada, dados no formato Penn Treebank \cite{buildingPTB}. O SP será melhor descrito em \ref{sec:stanfordParser}.

% Para os \textit{parsers} convencionais, utilizamos os motores de busca supracitados, pesquisando por \textit{parser}, \textit{parsing}, \textit{constituency parser}. Durante a revisão de literatura, e em diálogos com especialistas, conhecemos o \textit{Stanford Parser}, que utiliza dados no formato \textit{Penn treebank}. Optamos por utilizá-lo.

Percebeu-se, então, a necessidade de realizar uma adaptação entre bancos de árvores, iniciando-se a Terceira etapa, de referencial teórico para a transdução.

Para a adaptação entre bancos de árvores, estudou-se a estrutura dos bancos originais, por observação de exemplos. De acordo com as necessidades observadas, estudamos os manuais de cada um, que conste: O Manual de \textit{bracketing} do Penn Treebann \cite{bracketing_ptb}, Manual de classificação do Penn Treebank \cite{buildingPTB}, Manual da Bíblia Florestal \cite{freitas2007biblia} e Manual de LxParser \cite{siteLxParser}. Com a necessidade de aprofundamento, estudou-se também o manual do formato 
Árvores Deitadas, utilizado no BOSQUE \cite{afonso2006arvores} e o Manual do Cintil \cite{cintil_handbook}. Neste contexto, foi desenvolvida a metodologia de transdução de \textit{parsers}, que será abordada neste trabalho. 

Na Quarta etapa, foi feita a transdução de bancos de árvores propriamente dita. O \textit{transdutor} foi desenvolvido na linguagem Python, pela afinidade do autor com a mesma. O desenvolvimento teve como objetivo realizar a transdução de modo a conservar a informação lexical dos dados originais, adaptando apenas a sua estrutura para que possam ser consumidos pelo supra-citado Stanford Parser. Como dito anteriormente, este \textit{parser} recebe como entrada árvores no formato Penn Treebank (PTB). Portanto, os bancos de árvores selecionados na etapa Um foram transduzidos para o formato PTB.
% Em casos onde foi obrigatória a adaptação do formato da sentença classificada, esforçou-se para realizar o mínimo de impacto na árvore resultante. 
A discussão aprofundada do método de transdução será realizada no Capítulo \ref{cap:desenv}.

A Quinta etapa envolveu o treino do Stanford Parser propriamente dito. Em nenhum momento houve implementação sobre o \textit{parser}. Foi realizado apenas o processo de transdução, treinamento e avaliação. Para o uso do \textit{parser}, foi utilizada a sua interface de terminal (\textit{command line interface}, CLI). O treino foi feito utilizando o método \textit{10-fold validation}, para possibilitar uma média de avaliação. Os procedimentos de treino serão comentados nas sessões \ref{treinando_sp_cintil} e \ref{sec:treinando_sp_bosque}.

% As sentenças pré-classificadas transduzidas foram utilizadas para treinar o \textit{parser} escolhido. Optou-se por não realizar desenvolvimento de código diretamente sobre \textit{parser}. Portanto, foi utilizada a interface por terminal (\textit{command line interface}, CLI). Usou-se o método \textit{10-fold validation}, para obter diversas métricas de treino, que pudessem ser comparadas entre si, e com os resultados do outro conjunto de dados transduzidos.

% O classificador em questão imprime os resultados de treino por padrão. Tais resultados foram coletados, catalogados, e analisados. A análise foi feita, primeiramente, separando os resultados de cada conjunto de dados, e depois comparando-os.
Por fim, na Sexta etapa foi feito o cruzamento dos dados obtidos, suas análises e considerações, que serão demonstradas na sessão \ref{resultados}. 